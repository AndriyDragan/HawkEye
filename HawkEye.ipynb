{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detection and Classification of Military Planes: A Comparative Study of YOLO, Faster R-CNN, RetinaNet, and EfficientDet\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In the midst of the ongoing war in Ukraine, the ability to accurately detect and classify military aircraft is of critical importance for surveillance, defense, and strategic planning. This capability can significantly contribute to national security and defense efforts.\n",
        "\n",
        "With the availability of advanced models such as YOLO (You Only Look Once), Faster R-CNN, RetinaNet, and EfficientDet, the potential for higher accuracy and faster detection speeds has increased.\n",
        "\n",
        "This project seeks to explore and compare the performance of these advanced models for the task of military aircraft detection and classification. By conducting this comparative study, I aim to identify the most suitable model for practical applications in military contexts.\n",
        "\n",
        "I have decided to use a Military Aircraft Recognition dataset from Kaggle. This dataset includes 3842 images, 20 types, and 22341 instances annotated with horizontal bounding boxes and oriented bounding boxes.\n",
        "\n",
        "In order to simplify the work, I have downloaded the entire dataset into my Git repository. Let's start by importing our project code and data from the Git repository:\n"
      ],
      "metadata": {
        "id": "TO5qg9_qTCNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/AndriyDragan/HawkEye.git\n",
        "\n",
        "# Install YOLOv5\n",
        "%pip install -U ultralytics\n",
        "\n",
        "# Install TensorFlow Object Detection API dependencies\n",
        "%pip install tensorflow tf_slim\n",
        "\n",
        "# Clone the TensorFlow models repository\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# Install additional dependencies\n",
        "%cd models/research\n",
        "%protoc object_detection/protos/*.proto --python_out=.\n",
        "%pip install .\n",
        "%pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "S4a6qO7QokfN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis and Preparation"
      ],
      "metadata": {
        "id": "GT7vjcNDe_zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by importing the dependencies and examining the data:"
      ],
      "metadata": {
        "id": "WClbr0JAF04r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YBLUJcItxCVY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2ef4cf98-2618-4916-aa3e-35f6ff3a354b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'FasterRCNNFeatureExtractor' from 'transformers' (/usr/local/lib/python3.10/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ad50b798bd7b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFasterRCNNFeatureExtractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFasterRCNNForObjectDetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FasterRCNNFeatureExtractor' from 'transformers' (/usr/local/lib/python3.10/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import datetime\n",
        "import itertools\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import Counter, defaultdict, deque\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import torch\n",
        "from transformers import FasterRCNNFeatureExtractor, FasterRCNNForObjectDetection\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torchvision.transforms as T\n",
        "from torchvision.ops import box_iou\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, retinanet_resnet50_fpn, RetinaNet_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.retinanet import RetinaNetHead\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from ultralytics import YOLO\n",
        "from effdet import create_model, DetBenchTrain\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "data_dir = 'HawkEye/Data'\n",
        "\n",
        "imfiles = os.listdir(os.path.join(data_dir, 'Images'))\n",
        "imfiles = [os.path.join(data_dir, 'Images', f) for f in imfiles if os.path.splitext(f)[-1] == '.jpg']\n",
        "\n",
        "def imread(filename):\n",
        "    return cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sample = random.choice(imfiles)\n",
        "image = imread(sample)\n",
        "rows, cols, channels = image.shape\n",
        "\n",
        "plt.imshow(image)\n",
        "print('Number of samples:', len(imfiles))\n",
        "print('Image shape:      ', image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifying Image Sizes\n",
        "To ensure consistency, we'll check the dimensions of all images:"
      ],
      "metadata": {
        "id": "CzdFMvb_NdkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the count of images for each shape\n",
        "image_shapes = defaultdict(int)\n",
        "\n",
        "for imfile in tqdm(imfiles):\n",
        "    image = cv2.imread(imfile)\n",
        "    if image is not None:\n",
        "        shape = image.shape\n",
        "        image_shapes[shape] += 1\n",
        "\n",
        "# Iterate over all images and collect information about their shapes\n",
        "for shape, count in image_shapes.items():\n",
        "    print(f'Shape: {shape}, Count: {count}')"
      ],
      "metadata": {
        "id": "lgvf-4xZGPEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe a variety of image shapes. The main cluster is (800, 800, 3), which will be the base of our dataset."
      ],
      "metadata": {
        "id": "kdBvLSHjN0Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Annotations"
      ],
      "metadata": {
        "id": "iK0YcbG9LPJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read annotations\n",
        "def read_annotations(xml_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    annotations = []\n",
        "    for obj in root.findall('object'):\n",
        "        name = obj.find('name').text\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "        annotations.append((name, (xmin, ymin, xmax, ymax)))\n",
        "    return annotations\n",
        "\n",
        "\n",
        "def read_data(file_names, data_dir):\n",
        "    data = []\n",
        "    labels = []\n",
        "    dims = []\n",
        "\n",
        "    for file_name in file_names:\n",
        "        img_path = os.path.join(data_dir, 'Images', file_name + '.jpg')\n",
        "        xml_path = os.path.join(data_dir, 'Labels', 'Horizontal Bounding Boxes', file_name + '.xml')\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if img.size != (800, 800):\n",
        "            continue\n",
        "\n",
        "        annotations = read_annotations(xml_path)\n",
        "\n",
        "        for annot in annotations:\n",
        "            width = abs(annot[1][0] - annot[1][2])\n",
        "            height = abs(annot[1][1] - annot[1][3])\n",
        "            dims.append((width, height))\n",
        "            labels.append(annot[0])\n",
        "\n",
        "        data.append((img_path, xml_path, (width, height)))\n",
        "\n",
        "    return data, labels, dims\n",
        "\n",
        "file_names = [f.split('.')[0] for f in os.listdir(os.path.join(data_dir, 'Images'))]\n",
        "data, labels, dims = read_data(file_names, data_dir)\n"
      ],
      "metadata": {
        "id": "-y5QE3TJE2uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying Random Samples with Annotations\n",
        "Let's display some random samples from our dataset with proper annotations:"
      ],
      "metadata": {
        "id": "Lr28zpTmIWTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random samples\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax in axes:\n",
        "    idx = np.random.randint(0, len(data) - 1)\n",
        "    img_path, xml_path, _ = data[idx]\n",
        "    img = Image.open(img_path)\n",
        "    annotations = read_annotations(xml_path)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for obj in annotations:\n",
        "        label, (xmin, ymin, xmax, ymax) = obj\n",
        "        draw.rectangle([xmin, ymin, xmax, ymax], outline='red')\n",
        "        font_size = 20\n",
        "        draw.text((xmax, ymin), label, fill='red')\n",
        "\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2vWbPWDKWLW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will visualize additional properties of the dataset, such as per-class histogram and brightness distribution:"
      ],
      "metadata": {
        "id": "uMnWx75sPqId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot the per-class histogram\n",
        "hist = Counter(labels)\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.bar(hist.keys(), hist.values())\n",
        "plt.grid(True)\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Per-Class Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xh6XxgeVe-iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the per-class distribution\n",
        "sorted_hist = dict(sorted(hist.items()))\n",
        "for class_label, count in sorted_hist.items():\n",
        "    print(f'Class {class_label}: {count} instances')"
      ],
      "metadata": {
        "id": "lr7XAh8typgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a random subset of the dataset for brightness analysis\n",
        "sample_size = 1000\n",
        "sample_data_indices = np.random.choice(len(data), sample_size, replace=False)\n",
        "brightness = []\n",
        "\n",
        "for idx in sample_data_indices:\n",
        "    img_path = data[idx][0]\n",
        "    img = Image.open(img_path).convert('L')\n",
        "    brightness.append(np.mean(np.array(img)))\n",
        "\n",
        "sample_brightness = pd.DataFrame(brightness, columns=['Brightness'])\n",
        "\n",
        "# Plot brightness distribution for the sample\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.hist(sample_brightness['Brightness'], bins=50, alpha=0.7)\n",
        "plt.xlabel('Brightness')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Brightness Distribution (Sample)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ju4oITVxrIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Brightness distribution per class for the sample\n",
        "sample_labels = [labels[idx] for idx in sample_data_indices]\n",
        "brightness_per_class = pd.DataFrame({'ClassId': sample_labels, 'Brightness': brightness}).groupby('ClassId')['Brightness'].mean()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.bar(brightness_per_class.index, brightness_per_class.values)\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Average Brightness')\n",
        "plt.title('Average Brightness per Class (Sample)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y83xV1plA9me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am a bit worried by severely unequal per-class distribution and would like to mitigate the risks of some classes undertraining. At first I decided that simplest pass would be to remove overepresented classes. Lets take maximum of 500 images of each class."
      ],
      "metadata": {
        "id": "4Uq8FO_RQbap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter to count instances of each class\n",
        "def filter_data(data, class_counter, max_count):\n",
        "    new_data = []\n",
        "    new_class_counter = {class_name: 0 for class_name in class_counter}\n",
        "    for img_path, xml_path, dimensions in data:\n",
        "        annotations = read_annotations(xml_path)\n",
        "        filtered_annotations = []\n",
        "        for annot in annotations:\n",
        "            class_name = annot[0]\n",
        "            if new_class_counter[class_name] < max_count:\n",
        "                filtered_annotations.append(annot)\n",
        "                new_class_counter[class_name] += 1\n",
        "        if filtered_annotations:\n",
        "            new_data.append((img_path, xml_path, dimensions))\n",
        "    return new_data\n",
        "\n",
        "class_counter = Counter(labels)\n",
        "max_count = 500\n",
        "filtered_data = filter_data(data, class_counter, max_count)\n",
        "\n",
        "# Update labels based on filtered_data\n",
        "new_labels = []\n",
        "for img_path, xml_path, dimensions in filtered_data:\n",
        "    annotations = read_annotations(xml_path)\n",
        "    for annot in annotations:\n",
        "        new_labels.append(annot[0])\n",
        "\n",
        "# Recount instances of each class in the new dataset\n",
        "new_class_counter = Counter(new_labels)\n",
        "sorted_new_class_counter = dict(sorted(new_class_counter.items()))\n",
        "\n",
        "# Print new statistics\n",
        "for class_label, count in sorted_new_class_counter.items():\n",
        "    print(f'Class {class_label}: {count} instances')"
      ],
      "metadata": {
        "id": "6Fq4W7WcGdJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the updated per-class histogram\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.bar(sorted_new_class_counter.keys(), sorted_new_class_counter.values())\n",
        "plt.grid(True)\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Per-Class Histogram After Filtering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lUU57sWSfV5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes I made my dataset much smaller yet I belive its optimal option to mitigate issues of class imbalance. I have no time to look for more data and using proper data augmentation is also out of scope of this project. But I will use pre-trained models and hope this data will be enough  for finetuning."
      ],
      "metadata": {
        "id": "qE1-4FA5yWPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of class names in the order of their class IDs\n",
        "class_names = ['A1', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A2', 'A20', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "random.shuffle(filtered_data)\n",
        "split_index = int(0.8 * len(filtered_data))\n",
        "train_data = filtered_data[:split_index]\n",
        "val_data = filtered_data[split_index:]\n",
        "\n",
        "# Write paths to image and XML annotation files\n",
        "def write_data_to_file(data, file_path):\n",
        "    with open(file_path, 'w') as f:\n",
        "        for img_path, xml_path, _ in data:\n",
        "            f.write(f\"{img_path}\\t{xml_path}\\n\")\n",
        "\n",
        "# Use new file names for image-annotation pairs to avoid overwriting\n",
        "write_data_to_file(train_data, os.path.join(data_dir, 'DataLists', 'train.txt'))\n",
        "write_data_to_file(val_data, os.path.join(data_dir, 'DataLists', 'test.txt'))"
      ],
      "metadata": {
        "id": "9Qs5s4SukEQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO"
      ],
      "metadata": {
        "id": "Nesa4v_Ot28d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Function to parse XML and convert to YOLO format\n",
        "def convert_xml_to_yolo(xml_path, img_size=(800, 800)):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    yolo_data = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        name = obj.find('name').text\n",
        "        class_id = class_names.index(name)\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format\n",
        "        x_center = (xmin + xmax) / 2 / img_size[0]\n",
        "        y_center = (ymin + ymax) / 2 / img_size[1]\n",
        "        width = (xmax - xmin) / img_size[0]\n",
        "        height = (ymax - ymin) / img_size[1]\n",
        "\n",
        "        yolo_data.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    return yolo_data\n",
        "\n",
        "# Function to copy files based on file path lists and convert labels\n",
        "def copy_and_convert_files(file_list, img_dest, lbl_dest):\n",
        "    with open(file_list, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) != 2:\n",
        "                print(f\"Skipping line due to unexpected format: {line}\")\n",
        "                continue\n",
        "            img_path, xml_path = parts\n",
        "            shutil.copy(img_path, img_dest)\n",
        "\n",
        "            # Convert XML to YOLO and save\n",
        "            yolo_data = convert_xml_to_yolo(xml_path)\n",
        "            yolo_lbl_path = os.path.join(lbl_dest, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
        "            with open(yolo_lbl_path, 'w') as lbl_file:\n",
        "                lbl_file.write(\"\\n\".join(yolo_data))\n",
        "\n",
        "# Create directories for YOLO dataset\n",
        "yolo_base_dir = '/content/datasets/dataset'\n",
        "train_img_dir = os.path.join(yolo_base_dir, 'train/images')\n",
        "train_lbl_dir = os.path.join(yolo_base_dir, 'train/labels')\n",
        "val_img_dir = os.path.join(yolo_base_dir, 'val/images')\n",
        "val_lbl_dir = os.path.join(yolo_base_dir, 'val/labels')\n",
        "\n",
        "os.makedirs(train_img_dir, exist_ok=True)\n",
        "os.makedirs(train_lbl_dir, exist_ok=True)\n",
        "os.makedirs(val_img_dir, exist_ok=True)\n",
        "os.makedirs(val_lbl_dir, exist_ok=True)\n",
        "\n",
        "# Copy and convert training and validation files\n",
        "copy_and_convert_files(os.path.join(data_dir, 'DataLists', 'train.txt'), train_img_dir, train_lbl_dir)\n",
        "copy_and_convert_files(os.path.join(data_dir, 'DataLists', 'test.txt'), val_img_dir, val_lbl_dir)"
      ],
      "metadata": {
        "id": "dmtYVbuyJMM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data.yaml with correct paths\n",
        "data_yaml_content = f\"\"\"\n",
        "train: {os.path.join(yolo_base_dir, 'train')}\n",
        "val: {os.path.join(yolo_base_dir, 'val')}\n",
        "nc: {len(set(labels))}\n",
        "names: {list(set(labels))}\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "    f.write(data_yaml_content)"
      ],
      "metadata": {
        "id": "y9twhq7_uGyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLO\n",
        "yolo_model = YOLO('yolov5su.pt')\n",
        "\n",
        "# Capture training history\n",
        "yolo_model.train(data='data.yaml', epochs=10, imgsz=800)\n",
        "\n",
        "# Validate YOLO\n",
        "yolo_results = yolo_model.val()\n",
        "print(yolo_results)\n"
      ],
      "metadata": {
        "id": "t4RXzPUHBzru",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115b74d6-10fb-43eb-b2eb-dd5b68e7ccb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5su.pt to 'yolov5su.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17.7M/17.7M [00:00<00:00, 139MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.74 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 25.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=20\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2123788  ultralytics.nn.modules.head.Detect           [20, [128, 256, 512]]         \n",
            "YOLOv5s summary: 262 layers, 9,129,932 parameters, 9,129,916 gradients, 24.1 GFLOPs\n",
            "\n",
            "Transferred 421/427 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 111MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/dataset/train/labels... 1471 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1471/1471 [00:01<00:00, 1331.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/val/labels... 368 images, 0 backgrounds, 0 corrupt: 100%|██████████| 368/368 [00:00<00:00, 1168.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dataset/val/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 800 train, 800 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      6.02G      1.252      3.503      1.242         85        800: 100%|██████████| 92/92 [00:26<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.316      0.488      0.306       0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      5.91G      1.032      2.192      1.075         88        800: 100%|██████████| 92/92 [00:21<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.432      0.557      0.474      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      5.95G     0.9928      1.757      1.047        103        800: 100%|██████████| 92/92 [00:21<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.515      0.618      0.603      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      5.93G     0.9461      1.477      1.027         96        800: 100%|██████████| 92/92 [00:21<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.649      0.693      0.711       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      5.93G     0.9101      1.241      1.011         75        800: 100%|██████████| 92/92 [00:21<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:02<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.723      0.738      0.786      0.605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      5.91G      0.899      1.071       1.01         72        800: 100%|██████████| 92/92 [00:21<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.809      0.796       0.86      0.668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      5.91G     0.8578     0.9293     0.9891         62        800: 100%|██████████| 92/92 [00:21<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.777      0.812      0.864      0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10       5.9G     0.8358     0.8148     0.9866         63        800: 100%|██████████| 92/92 [00:21<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:02<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.815       0.87      0.901      0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      5.92G      0.822     0.7431     0.9717         78        800: 100%|██████████| 92/92 [00:21<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:02<00:00,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.897      0.864      0.931      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      5.93G     0.7901     0.6603     0.9573         97        800: 100%|██████████| 92/92 [00:21<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:02<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.906      0.904      0.949      0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.074 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 18.6MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 18.6MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.74 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "YOLOv5s summary (fused): 193 layers, 9,119,276 parameters, 0 gradients, 23.9 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.906      0.904      0.949      0.763\n",
            "                   A14         28        136      0.795      0.829      0.874      0.716\n",
            "                   A12         16         74      0.923      0.973      0.992      0.825\n",
            "                    A2         40         97      0.922      0.907      0.946      0.764\n",
            "                    A1         38        122      0.944      0.943      0.986      0.807\n",
            "                   A11         22        110      0.974      0.818      0.961      0.684\n",
            "                   A19         45        141      0.736      0.993       0.93      0.773\n",
            "                   A10         22         78      0.852      0.872      0.911      0.711\n",
            "                    A9         12         98      0.985      0.908      0.962      0.762\n",
            "                    A7         50        165      0.976          1      0.995      0.812\n",
            "                    A8         14         30      0.843      0.539        0.8      0.686\n",
            "                   A17         33        109      0.771      0.835      0.889      0.697\n",
            "                   A18         35        111      0.928      0.923      0.971      0.776\n",
            "                   A13         21         85      0.952      0.935      0.964      0.774\n",
            "                    A5         32        105      0.875      0.931      0.974      0.775\n",
            "                   A16         11         63      0.885      0.921      0.929      0.767\n",
            "                    A6         20         86      0.851      0.907       0.95      0.688\n",
            "                    A3         18         78          1       0.95      0.994      0.801\n",
            "                   A20         32        113      0.989      0.982      0.995      0.862\n",
            "                   A15         22         91      0.957      0.978      0.986      0.834\n",
            "                    A4         26        123      0.958       0.93      0.978      0.751\n",
            "Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics YOLOv8.2.74 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "YOLOv5s summary (fused): 193 layers, 9,119,276 parameters, 0 gradients, 23.9 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/val/labels.cache... 368 images, 0 backgrounds, 0 corrupt: 100%|██████████| 368/368 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   9%|▊         | 2/23 [00:01<00:10,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ NMS time limit 2.800s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        368       2015      0.905      0.899      0.945      0.759\n",
            "                   A14         28        136      0.795      0.831      0.874      0.715\n",
            "                   A12         16         74      0.923      0.973      0.992      0.828\n",
            "                    A2         40         97       0.92      0.907      0.946      0.769\n",
            "                    A1         38        122      0.944      0.943      0.986      0.806\n",
            "                   A11         22        110      0.974      0.818      0.961      0.683\n",
            "                   A19         45        141      0.737      0.993       0.93      0.772\n",
            "                   A10         22         78       0.85      0.872       0.91      0.709\n",
            "                    A9         12         98      0.985      0.908      0.962      0.759\n",
            "                    A7         50        165      0.976      0.976      0.976      0.795\n",
            "                    A8         14         30      0.844       0.54        0.8      0.675\n",
            "                   A17         33        109      0.765      0.836       0.89      0.694\n",
            "                   A18         35        111      0.928      0.923      0.971      0.772\n",
            "                   A13         21         85      0.952      0.935      0.964       0.78\n",
            "                    A5         32        105      0.875      0.931      0.974      0.778\n",
            "                   A16         11         63      0.884      0.921      0.929      0.768\n",
            "                    A6         20         86      0.852      0.907       0.95      0.687\n",
            "                    A3         18         78          1       0.95      0.994      0.805\n",
            "                   A20         32        113      0.988      0.912      0.929      0.805\n",
            "                   A15         22         91      0.956      0.978      0.986      0.836\n",
            "                    A4         26        123      0.958       0.93      0.978      0.751\n",
            "Speed: 0.4ms preprocess, 6.8ms inference, 0.0ms loss, 12.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79703c1e45b0>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.037091,    0.018545,           0],\n",
            "       [          1,           1,           1, ...,     0.85057,     0.85057,           0],\n",
            "       [          1,           1,           1, ...,     0.22299,     0.22299,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,   0.0032882,   0.0016441,           0],\n",
            "       [          1,           1,           1, ...,     0.22922,     0.22922,           0],\n",
            "       [          1,           1,           1, ...,     0.38801,     0.38801,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.23957,     0.23957,     0.33753, ...,           0,           0,           0],\n",
            "       [    0.12937,     0.12951,     0.24014, ...,           0,           0,           0],\n",
            "       [    0.17831,     0.17831,     0.27094, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.20669,     0.20712,     0.44183, ...,           0,           0,           0],\n",
            "       [    0.18182,     0.18182,     0.26255, ...,           0,           0,           0],\n",
            "       [    0.20795,     0.20807,     0.35588, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.13623,     0.13623,     0.20365, ...,           1,           1,           1],\n",
            "       [   0.069159,    0.069238,     0.13646, ...,           1,           1,           1],\n",
            "       [   0.097881,    0.097881,      0.1567, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.11628,     0.11655,     0.28982, ...,           1,           1,           1],\n",
            "       [        0.1,         0.1,     0.15111, ...,           1,           1,           1],\n",
            "       [    0.11604,     0.11611,     0.21645, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.99265,     0.99265,     0.98529, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [     0.9292,      0.9292,      0.9292, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: 0.7778513407706643\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.71459,     0.82761,      0.7685,     0.80587,     0.68268,     0.77193,     0.70926,     0.75893,     0.79545,     0.67542,     0.69378,     0.77196,     0.77951,     0.77817,     0.76831,      0.6873,     0.80467,     0.80483,     0.83591,     0.75059])\n",
            "names: {0: 'A14', 1: 'A12', 2: 'A2', 3: 'A1', 4: 'A11', 5: 'A19', 6: 'A10', 7: 'A9', 8: 'A7', 9: 'A8', 10: 'A17', 11: 'A18', 12: 'A13', 13: 'A5', 14: 'A16', 15: 'A6', 16: 'A3', 17: 'A20', 18: 'A15', 19: 'A4'}\n",
            "plot: True\n",
            "results_dict: {'metrics/precision(B)': 0.905297348233393, 'metrics/recall(B)': 0.8991455705261646, 'metrics/mAP50(B)': 0.9451455080909573, 'metrics/mAP50-95(B)': 0.7592630999572983, 'fitness': 0.7778513407706643}\n",
            "save_dir: PosixPath('runs/detect/train2')\n",
            "speed: {'preprocess': 0.3665951283081718, 'inference': 6.822988390922546, 'loss': 0.037821090739706284, 'postprocess': 12.199726441632146}\n",
            "task: 'detect'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load results.csv\n",
        "results_file = 'runs/detect/train/results.csv'\n",
        "df = pd.read_csv(results_file)\n",
        "\n",
        "# Print column names to inspect them\n",
        "print(df.columns)\n",
        "\n",
        "# Strip leading and trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Extract metrics using the stripped column names\n",
        "epochs = df['epoch']\n",
        "train_loss = df['train/box_loss'] + df['train/cls_loss'] + df['train/dfl_loss']\n",
        "train_accuracy = df['metrics/mAP50(B)']  # Assuming mAP50 is used as a proxy for accuracy\n",
        "\n",
        "# Plot metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs, train_loss, label='Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, train_accuracy, label='Train Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DR1LwPb_9vhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "2d22d946-a39a-40a6-f066-f52030e4117a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['                  epoch', '         train/box_loss',\n",
            "       '         train/cls_loss', '         train/dfl_loss',\n",
            "       '   metrics/precision(B)', '      metrics/recall(B)',\n",
            "       '       metrics/mAP50(B)', '    metrics/mAP50-95(B)',\n",
            "       '           val/box_loss', '           val/cls_loss',\n",
            "       '           val/dfl_loss', '                 lr/pg0',\n",
            "       '                 lr/pg1', '                 lr/pg2'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jGjV-frTueaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up TensorFlow Object Detection API"
      ],
      "metadata": {
        "id": "AjDhtn0uOwgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "# Define paths\n",
        "WORKSPACE_PATH = os.path.join('Tensorflow', 'workspace')\n",
        "SCRIPTS_PATH = os.path.join('Tensorflow', 'scripts')\n",
        "APIMODEL_PATH = os.path.join('Tensorflow', 'models')\n",
        "ANNOTATION_PATH = os.path.join(WORKSPACE_PATH, 'annotations')\n",
        "IMAGE_PATH = os.path.join(WORKSPACE_PATH, 'images')\n",
        "MODEL_PATH = os.path.join(WORKSPACE_PATH, 'models')\n",
        "PRETRAINED_MODEL_PATH = os.path.join(WORKSPACE_PATH, 'pre-trained-models')\n",
        "CONFIG_PATH = os.path.join(MODEL_PATH, 'my_ssd_mobnet', 'pipeline.config')\n",
        "CHECKPOINT_PATH = os.path.join(MODEL_PATH, 'my_ssd_mobnet')\n",
        "\n",
        "# Create necessary folders\n",
        "!mkdir -p {ANNOTATION_PATH} {IMAGE_PATH} {MODEL_PATH} {PRETRAINED_MODEL_PATH}\n",
        "\n",
        "# Copy the pre-trained model files from TensorFlow Model Zoo\n",
        "!wget -P {PRETRAINED_MODEL_PATH} http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "!wget -P {PRETRAINED_MODEL_PATH} http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_coco17_tpu-32.tar.gz\n",
        "!wget -P {PRETRAINED_MODEL_PATH} http://download.tensorflow.org/models/object_detection/tf2/20200711/retinanet_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Extract the models\n",
        "!tar -zxvf {PRETRAINED_MODEL_PATH}/efficientdet_d0_coco17_tpu-32.tar.gz -C {PRETRAINED_MODEL_PATH}\n",
        "!tar -zxvf {PRETRAINED_MODEL_PATH}/faster_rcnn_resnet50_coco17_tpu-32.tar.gz -C {PRETRAINED_MODEL_PATH}\n",
        "!tar -zxvf {PRETRAINED_MODEL_PATH}/retinanet_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz -C {PRETRAINED_MODEL_PATH}"
      ],
      "metadata": {
        "id": "jHRglyUbO5To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the environment\n",
        "%pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "m_ZEh1eEPDTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the Pipeline Configuration Files"
      ],
      "metadata": {
        "id": "Jmv_EDNOQoyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the configuration file\n",
        "config_path = os.path.join(PRETRAINED_MODEL_PATH, 'efficientdet_d0_coco17_tpu-32', 'pipeline.config')\n",
        "config = config_util.get_configs_from_pipeline_file(config_path)\n",
        "\n",
        "# Update the number of classes\n",
        "config['model']['ssd']['num_classes'] = len(class_names)\n",
        "\n",
        "# Update fine_tune_checkpoint\n",
        "config['train_config']['fine_tune_checkpoint'] = os.path.join(PRETRAINED_MODEL_PATH, 'efficientdet_d0_coco17_tpu-32', 'checkpoint', 'ckpt-0')\n",
        "\n",
        "# Update label_map_path\n",
        "config['train_input_reader']['label_map_path'] = os.path.join(ANNOTATION_PATH, 'label_map.pbtxt')\n",
        "config['eval_input_reader']['label_map_path'] = os.path.join(ANNOTATION_PATH, 'label_map.pbtxt')\n",
        "\n",
        "# Update the input paths\n",
        "config['train_input_reader']['tf_record_input_reader']['input_path'] = [os.path.join(ANNOTATION_PATH, 'train.record')]\n",
        "config['eval_input_reader']['tf_record_input_reader']['input_path'] = [os.path.join(ANNOTATION_PATH, 'val.record')]\n",
        "\n",
        "# Save the modified pipeline config\n",
        "config_util.save_pipeline_config(config, WORKSPACE_PATH)"
      ],
      "metadata": {
        "id": "og41xcwKQkuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R-CNN"
      ],
      "metadata": {
        "id": "-rIPYySAYChZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Faster R-CNN\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'faster_rcnn_resnet50_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'faster_rcnn')} \\\n",
        "    --alsologtostderr"
      ],
      "metadata": {
        "id": "fgSe259sYlrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RetinaNet"
      ],
      "metadata": {
        "id": "l3V6hPS9CJYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RetinaNet\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'retinanet_resnet50_v1_fpn_640x640_coco17_tpu-8', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'retinanet')} \\\n",
        "    --alsologtostderr"
      ],
      "metadata": {
        "id": "Lkm5iZKiCLhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientDet"
      ],
      "metadata": {
        "id": "cJD-z_Ydud4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train EfficientDet\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'efficientdet_d0_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'efficientdet')} \\\n",
        "    --alsologtostderr"
      ],
      "metadata": {
        "id": "BknYp2XGCHRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the models"
      ],
      "metadata": {
        "id": "E4gSemLVukmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Faster R-CNN\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'faster_rcnn_resnet50_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'faster_rcnn')} \\\n",
        "    --checkpoint_dir={os.path.join(MODEL_PATH, 'faster_rcnn')} \\\n",
        "    --alsologtostderr \\\n",
        "    --eval_on_train_data\n",
        "\n",
        "# Evaluate RetinaNet\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'retinanet_resnet50_v1_fpn_640x640_coco17_tpu-8', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'retinanet')} \\\n",
        "    --checkpoint_dir={os.path.join(MODEL_PATH, 'retinanet')} \\\n",
        "    --alsologtostderr \\\n",
        "    --eval_on_train_data\n",
        "\n",
        "# Evaluate EfficientDet\n",
        "!python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={os.path.join(PRETRAINED_MODEL_PATH, 'efficientdet_d0_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --model_dir={os.path.join(MODEL_PATH, 'efficientdet')} \\\n",
        "    --checkpoint_dir={os.path.join(MODEL_PATH, 'efficientdet')} \\\n",
        "    --alsologtostderr \\\n",
        "    --eval_on_train_data"
      ],
      "metadata": {
        "id": "wtiLQHcgusri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export the Trained Model for Inference"
      ],
      "metadata": {
        "id": "hc-svexkPhHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Faster R-CNN\n",
        "!python models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {os.path.join(PRETRAINED_MODEL_PATH, 'faster_rcnn_resnet50_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --trained_checkpoint_dir {os.path.join(MODEL_PATH, 'faster_rcnn')} \\\n",
        "    --output_directory {os.path.join(MODEL_PATH, 'exported_model/faster_rcnn')}\n",
        "\n",
        "# Export RetinaNet\n",
        "!python models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {os.path.join(PRETRAINED_MODEL_PATH, 'retinanet_resnet50_v1_fpn_640x640_coco17_tpu-8', 'pipeline.config')} \\\n",
        "    --trained_checkpoint_dir {os.path.join(MODEL_PATH, 'retinanet')} \\\n",
        "    --output_directory {os.path.join(MODEL_PATH, 'exported_model/retinanet')}\n",
        "\n",
        "# Export EfficientDet\n",
        "!python models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {os.path.join(PRETRAINED_MODEL_PATH, 'efficientdet_d0_coco17_tpu-32', 'pipeline.config')} \\\n",
        "    --trained_checkpoint_dir {os.path.join(MODEL_PATH, 'efficientdet')} \\\n",
        "    --output_directory {os.path.join(MODEL_PATH, 'exported_model/efficientdet')}"
      ],
      "metadata": {
        "id": "qYILDI0EPo0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion"
      ],
      "metadata": {
        "id": "vFR1bVrKu4Ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VdVNYb1ef1w4"
      }
    }
  ]
}